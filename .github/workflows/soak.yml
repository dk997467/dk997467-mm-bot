name: Soak Test (72h)

on:
  workflow_dispatch:
    inputs:
      duration_hours:
        description: 'Soak duration in hours'
        required: false
        default: '72'
        type: string
      mock_mode:
        description: 'Use mock data for testing'
        required: false
        default: false
        type: boolean

concurrency:
  group: soak-test
  cancel-in-progress: false

jobs:
  soak:
    name: Run Soak Test
    runs-on: ubuntu-latest
    timeout-minutes: 4380  # 73 hours max
    env:
      SOAK_OFFLINE: "1"
      BYBIT_API_KEY: "N/A"
      BYBIT_API_SECRET: "N/A"
      STORAGE_PG_PASSWORD: "N/A"
      # Safe fallbacks for inputs (available in all trigger contexts)
      DURATION_HOURS: ${{ github.event_name == 'workflow_dispatch' && inputs.duration_hours || '72' }}
      MOCK_MODE: ${{ github.event_name == 'workflow_dispatch' && inputs.mock_mode || false }}
      # PYTHONPATH for correct module imports
      PYTHONPATH: ${{ github.workspace }}
      # Soak artifacts directory for kpi_gate fallback
      SOAK_ARTIFACTS_DIR: artifacts/soak/latest
      # Soak output directory for iteration files
      SOAK_OUT_DIR: artifacts/soak/latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Minimal dependencies for soak runner
          # (stdlib-only script, no external deps needed)
      
      - name: Run soak test
        id: soak
        continue-on-error: true
        run: |
          MOCK_FLAG=""
          if [ "${{ env.MOCK_MODE }}" = "true" ]; then
            MOCK_FLAG="--mock"
          fi
          
          python -m tools.soak.run \
            --hours ${{ env.DURATION_HOURS }} \
            --export-json artifacts/reports/soak_metrics.json \
            --export-md artifacts/reports/SOAK_RESULTS.md \
            --gate-summary artifacts/reports/gates_summary.json \
            $MOCK_FLAG
          
          echo "EXIT_CODE=$?" >> $GITHUB_OUTPUT
      
      - name: List Soak Artifacts (Linux)
        if: always()
        working-directory: ${{ github.workspace }}
        run: |
          echo "================================================"
          echo "SOAK ARTIFACTS DIAGNOSTIC (Linux)"
          echo "================================================"
          echo "PWD=$(pwd)"
          echo "workspace=${{ github.workspace }}"
          echo "PYTHONPATH=$PYTHONPATH"
          echo "SOAK_ARTIFACTS_DIR=$SOAK_ARTIFACTS_DIR"
          echo "SOAK_OUT_DIR=$SOAK_OUT_DIR"
          echo ""
          echo "Artifacts in artifacts/soak/latest:"
          ls -lah artifacts/soak/latest || echo "Directory not found"
          echo ""
          echo "ITER_SUMMARY files:"
          ITER_COUNT=$(ls artifacts/soak/latest/ITER_SUMMARY_*.json 2>/dev/null | wc -l || echo 0)
          echo "Found $ITER_COUNT ITER_SUMMARY files"
          
          if [ "$ITER_COUNT" -eq "0" ]; then
            echo "::error::No ITER_SUMMARY_*.json produced in artifacts/soak/latest (check soak producer step)."
            echo "No ITER_SUMMARY files found - cannot run KPI gate"
            exit 1
          else
            ls -lah artifacts/soak/latest/ITER_SUMMARY_*.json
          fi
        shell: bash
      
      - name: Build Soak KPI (if builder exists)
        if: always()
        continue-on-error: true
        working-directory: ${{ github.workspace }}
        run: |
          if python -c "import importlib; importlib.import_module('tools.soak.build_soak_reports')" 2>/dev/null; then
            python -m tools.soak.build_soak_reports --in artifacts/soak/latest --out artifacts/soak/latest/SOAK_KPI.json
          else
            echo "[i] build_soak_reports not found — will gate by --iter mask"
          fi
        shell: bash
      
      - name: KPI Gate (explicit path or iter mask)
        if: always()
        continue-on-error: true
        working-directory: ${{ github.workspace }}
        run: |
          echo "================================================"
          echo "KPI GATE (Linux)"
          echo "================================================"
          if [ -f artifacts/soak/latest/SOAK_KPI.json ] && [ -s artifacts/soak/latest/SOAK_KPI.json ]; then
            echo "Using SOAK_KPI.json"
            python -m tools.soak.kpi_gate artifacts/soak/latest/SOAK_KPI.json
          else
            echo "Using ITER_SUMMARY glob"
            python -m tools.soak.kpi_gate --iter "artifacts/soak/latest/ITER_SUMMARY_*.json"
          fi
        shell: bash
      
      - name: Write readiness.json (Linux)
        if: always()
        continue-on-error: true
        working-directory: ${{ github.workspace }}
        run: |
          echo "================================================"
          echo "WRITING READINESS.JSON (Linux)"
          echo "================================================"
          python -m tools.soak.write_readiness \
            --iter-glob "artifacts/soak/latest/ITER_SUMMARY_*.json" \
            --out "artifacts/reports/readiness.json" \
            --min_maker_taker 0.83 --min_edge 2.9 --max_latency 330 --max_risk 0.40
          echo ""
          if [ -f artifacts/reports/readiness.json ]; then
            echo "✓ readiness.json created:"
            cat artifacts/reports/readiness.json
          else
            echo "⚠ readiness.json not created"
          fi
        shell: bash
      
      - name: Post-Soak Analyzer V2 (trends, sparklines, violations)
        id: post-soak-analyzer
        if: always()
        continue-on-error: true
        working-directory: ${{ github.workspace }}
        run: |
          echo "================================================"
          echo "POST-SOAK ANALYZER V2"
          echo "================================================"
          
          mkdir -p artifacts/reports/analysis
          
          python -m tools.soak.analyze_post_soak \
            --iter-glob "artifacts/soak/latest/ITER_SUMMARY_*.json" \
            --min-windows 8 \
            --out-dir artifacts/reports/analysis \
            --warn-edge 2.5 --crit-edge 2.0 \
            --warn-maker 0.80 --crit-maker 0.75 \
            --warn-lat 350 --crit-lat 400 \
            --warn-risk 0.45 --crit-risk 0.50
          
          if [ $? -eq 0 ]; then
            echo "✓ Post-soak analysis completed"
            
            if [ -f artifacts/reports/analysis/POST_SOAK_ANALYSIS.md ]; then
              echo ""
              echo "=== Analysis Preview (first 30 lines) ==="
              head -30 artifacts/reports/analysis/POST_SOAK_ANALYSIS.md
            fi
            
            if [ -f artifacts/reports/analysis/VIOLATIONS.json ]; then
              echo ""
              echo "=== Violations Summary ==="
              cat artifacts/reports/analysis/VIOLATIONS.json
            fi
          else
            echo "⚠ Post-soak analysis returned non-zero exit code (non-blocking)"
          fi
        shell: bash
      
      - name: Upload soak artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: soak-test-results-${{ github.run_id }}
          path: |
            artifacts/reports/soak_metrics.json
            artifacts/reports/SOAK_RESULTS.md
            artifacts/reports/gates_summary.json
            artifacts/reports/readiness.json
            artifacts/reports/analysis/POST_SOAK_ANALYSIS.md
            artifacts/reports/analysis/RECOMMENDATIONS.md
            artifacts/reports/analysis/VIOLATIONS.json
            artifacts/reports/analysis/SOAK_SUMMARY.json
            artifacts/soak/latest/SOAK_KPI.json
            artifacts/soak/latest/ITER_SUMMARY_*.json
          if-no-files-found: warn
          retention-days: 90
      
      - name: Upload full artifacts on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: soak-failure-debug-${{ github.run_id }}
          path: |
            artifacts/**
            ./*.log
            **/*.err.log
          if-no-files-found: ignore
          retention-days: 30
      
      - name: Post Soak Summary to PR
        if: ${{ github.event_name == 'pull_request' }}
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const sumPath = 'artifacts/reports/analysis/SOAK_SUMMARY.json';
            
            if (!fs.existsSync(sumPath)) {
              core.warning('SOAK_SUMMARY.json not found, skipping comment.');
              return;
            }
            
            const sum = JSON.parse(fs.readFileSync(sumPath, 'utf8'));
            
            // Build comment
            let body = `### 🧪 Soak Analysis Summary\n\n`;
            body += `**Windows:** ${sum.windows} (min=${sum.min_windows_required}) | **Verdict:** `;
            
            // Verdict with emoji
            if (sum.overall.verdict === 'CRIT') {
              body += `🔴 **CRIT**`;
            } else if (sum.overall.verdict === 'WARN') {
              body += `🟡 **WARN**`;
            } else {
              body += `✅ **OK**`;
            }
            
            body += `\n\n`;
            body += `**Commit:** \`${sum.meta?.commit_range || 'n/a'}\` | **Profile:** \`${sum.meta?.profile || 'n/a'}\`\n\n`;
            
            // Per-symbol table
            body += `| Symbol | Edge(bps) | Trend | Maker/Taker | Trend | p95(ms) | Trend | Risk | Trend | Status |\n`;
            body += `|--------|-----------|-------|-------------|-------|---------|-------|------|-------|--------|\n`;
            
            for (const [sym, v] of Object.entries(sum.symbols)) {
              const edge = v.edge_bps;
              const maker = v.maker_taker_ratio;
              const lat = v.p95_latency_ms;
              const risk = v.risk_ratio;
              
              // Overall status for symbol (worst metric)
              let symbolStatus = 'OK';
              if ([edge.status, maker.status, lat.status, risk.status].includes('CRIT')) {
                symbolStatus = '🔴 CRIT';
              } else if ([edge.status, maker.status, lat.status, risk.status].includes('WARN')) {
                symbolStatus = '🟡 WARN';
              } else {
                symbolStatus = '✅ OK';
              }
              
              body += `| ${sym} | ${edge.last} | ${edge.trend} | ${maker.last} | ${maker.trend} | ${lat.last} | ${lat.trend} | ${risk.last} | ${risk.trend} | ${symbolStatus} |\n`;
            }
            
            body += `\n**Violations:** `;
            body += `🔴 CRIT: ${sum.overall.crit_count} | `;
            body += `🟡 WARN: ${sum.overall.warn_count} | `;
            body += `✅ OK: ${sum.overall.ok_count}\n\n`;
            
            body += `**Artifacts:** POST_SOAK_ANALYSIS.md, RECOMMENDATIONS.md, VIOLATIONS.json, SOAK_SUMMARY.json\n`;
            body += `(see workflow artifacts above)`;
            
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.pull_request.number,
              body
            });
      
      - name: Comment PR with results (if applicable)
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const mdPath = 'artifacts/reports/SOAK_RESULTS.md';
            
            if (!fs.existsSync(mdPath)) {
              console.log('No results file found');
              return;
            }
            
            const results = fs.readFileSync(mdPath, 'utf8');
            const exitCode = '${{ steps.soak.outputs.EXIT_CODE }}';
            
            const emoji = exitCode === '0' ? '✅' : '❌';
            const comment = `## ${emoji} Soak Test Results\n\n${results}`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      
      - name: Check soak test result
        if: always()
        run: |
          EXIT_CODE="${{ steps.soak.outputs.EXIT_CODE }}"
          
          if [ "$EXIT_CODE" = "0" ]; then
            echo "✅ Soak test PASSED"
            exit 0
          else
            echo "❌ Soak test FAILED"
            echo "Check uploaded artifacts for details"
            exit 1
          fi

