name: CI Memory Diagnostic

# This workflow is for DEEP DIAGNOSTICS ONLY
# It profiles memory usage to identify which tests cause OOM (exit 143)

on:
  workflow_dispatch:
    inputs:
      test_file:
        description: "Test file to analyze (test_selection_unit.txt or test_selection_e2e.txt)"
        required: true
        default: "test_selection_unit.txt"
        type: string
      batch_size:
        description: "Batch size (smaller = more isolated, slower)"
        required: false
        default: "3"
        type: string

jobs:
  memory-diagnostic:
    name: Memory Profiling & Diagnosis
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      PYTEST_DISABLE_PLUGIN_AUTOLOAD: "1"
      PYTHONPATH: "${{ github.workspace }}"
      BYBIT_API_KEY: "test_api_key_for_ci_only"
      BYBIT_API_SECRET: "test_api_secret_for_ci_only"
      STORAGE_PG_PASSWORD: "test_pg_password_for_ci_only"

    steps:
      - uses: actions/checkout@v4
      
      - name: Lint - forbid artifact v3
        run: |
          set -euo pipefail
          if git grep -nE 'actions/(upload|download)-artifact\s*[@:]\s*v3(\b|[^0-9])' .github | tee /dev/stderr; then
            echo "Found deprecated artifact actions v3 — must use @v4" >&2
            exit 1
          fi
      
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Rust toolchain
        uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          toolchain: stable

      - name: "[1/7] Prepare minimal requirements for CI"
        shell: bash
        run: |
          echo "=== Filtering requirements.txt ==="
          
          # Filter out private/local packages (case-insensitive, flexible matching)
          # Log filtered lines to stderr, only pass through clean dependencies to stdout
          awk '
            BEGIN{IGNORECASE=1}
            /^[[:space:]]*bybit-connector/ {print "  [FILTERED] " $0 > "/dev/stderr"; next}
            /^[[:space:]]*mm-orderbook/ {print "  [FILTERED] " $0 > "/dev/stderr"; next}
            /^[[:space:]]*mm_orderbook/ {print "  [FILTERED] " $0 > "/dev/stderr"; next}
            /^[[:space:]]*git\+ssh:/ {print "  [FILTERED] " $0 > "/dev/stderr"; next}
            /^[[:space:]]*git\+https:/ {print "  [FILTERED] " $0 > "/dev/stderr"; next}
            {print}
          ' requirements.txt > requirements_ci.txt
          
          # Add CI-specific overrides
          echo "pydantic>=2,<3"           >> requirements_ci.txt
          echo "pydantic-settings>=2,<3"  >> requirements_ci.txt
          echo "pandas>=2,<3"             >> requirements_ci.txt
          
          echo ""
          echo "=== Generated requirements_ci.txt ==="
          cat requirements_ci.txt
          
          echo ""
          echo "=== GATE: Verify mm-orderbook not in requirements_ci.txt ==="
          if grep -i "mm.orderbook\|mm_orderbook" requirements_ci.txt; then
            echo "❌ GATE FAILED: mm-orderbook found in requirements_ci.txt"
            echo "This should never happen - check AWK filter logic"
            exit 1
          fi
          echo "✓ GATE PASSED: mm-orderbook correctly filtered out"

      - name: "[2/7] Install base dependencies"
        run: |
          python -m pip install -U pip
          pip install maturin
          echo "✓ pip and maturin installed"

      - name: "[3/7] Install project with Rust module (editable)"
        run: |
          echo "=== Building and installing mm-bot with Rust extensions ==="
          pip install -e . -v
          echo ""
          echo "=== Smoke test: import mm_orderbook ==="
          python -c "import mm_orderbook; print('✓ mm_orderbook import OK')"

      - name: "[4/7] Install remaining dependencies + memory profiler"
        shell: bash
        run: |
          echo "=============================================="
          echo "Installing dependencies + pytest-memray"
          echo "=============================================="
          
          # Install external dependencies
          pip install -r requirements_ci.txt
          
          # Install memory profiler
          pip install pytest-memray
          
          echo ""
          echo "Installed packages:"
          pip list | grep -E "(pytest|memray)"

      - name: "[5/7] System resource snapshot (before tests)"
        run: |
          echo "=============================================="
          echo "SYSTEM RESOURCES (BEFORE TESTS)"
          echo "=============================================="
          echo ""
          echo "--- Memory (free -m) ---"
          free -m
          echo ""
          echo "--- Disk (df -h) ---"
          df -h
          echo ""
          echo "--- CPU Info ---"
          lscpu | grep -E "Model name|CPU\(s\)|Thread"
          echo ""
          echo "=============================================="

      - name: "[6/7] Run tests in batches with memory profiling"
        id: batch_tests
        continue-on-error: true
        run: |
          echo "=============================================="
          echo "BATCH TEST EXECUTION"
          echo "=============================================="
          echo "Test file: ${{ inputs.test_file }}"
          echo "Batch size: ${{ inputs.batch_size }}"
          echo ""
          
          # Run batch runner and capture exit code
          python tools/ci/test_batch_runner.py \
            --test-file "${{ inputs.test_file }}" \
            --batch-size "${{ inputs.batch_size }}" \
            --verbose
          
          # CRITICAL: Save exit code BEFORE any other commands
          EXIT_CODE=$?
          echo "EXIT_CODE=${EXIT_CODE}" >> $GITHUB_OUTPUT
          echo ""
          echo "Batch runner exit code: ${EXIT_CODE}"

      - name: "[7/7] System resource snapshot (after tests)"
        if: always()
        run: |
          echo "=============================================="
          echo "SYSTEM RESOURCES (AFTER TESTS)"
          echo "=============================================="
          echo ""
          echo "--- Memory (free -m) ---"
          free -m
          echo ""
          echo "--- Disk (df -h) ---"
          df -h
          echo ""
          echo "--- Top processes by memory ---"
          ps aux --sort=-%mem | head -20
          echo ""
          echo "=============================================="

      - name: "[extra] Analyze memory profiles"
        if: always()
        run: |
          echo "=============================================="
          echo "MEMORY PROFILE ANALYSIS"
          echo "=============================================="
          echo ""
          
          # Find any .bin files created by memray
          if ls *.bin 1> /dev/null 2>&1; then
            echo "Found memory profiles:"
            ls -lh *.bin
            echo ""
            
            # Analyze each profile
            for profile in *.bin; do
              echo "--- Analysis: $profile ---"
              python -m memray stats "$profile" || echo "Failed to analyze $profile"
              echo ""
            done
          else
            echo "No memory profiles found (.bin files)"
          fi

      - name: "[extra] Upload diagnostic artifacts"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: memory-diagnostic-${{ github.run_id }}
          path: |
            *.bin
            .pytest_cache/**
          if-no-files-found: warn
          retention-days: 7

      - name: "Summary: Check if diagnostic revealed failures"
        if: always()
        run: |
          echo "=============================================="
          echo "DIAGNOSTIC SUMMARY"
          echo "=============================================="
          
          exit_code="${{ steps.batch_tests.outputs.EXIT_CODE }}"
          
          if [ "$exit_code" = "0" ]; then
            echo "✅ All batches passed - no OOM detected"
            echo "This suggests the issue is with batch size or test combinations"
          elif [ "$exit_code" = "143" ]; then
            echo "❌ Exit 143 detected - OOM confirmed"
            echo "Check batch runner output above to see which batch failed"
          else
            echo "⚠️ Exit code: $exit_code"
            echo "Check batch runner output for details"
          fi
          
          echo ""
          echo "Next steps:"
          echo "1. Review batch runner output above"
          echo "2. Identify failing batch"
          echo "3. Run smaller batches on that subset"
          echo "4. Optimize identified problematic tests"

