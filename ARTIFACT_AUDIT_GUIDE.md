# Soak Artifact Audit Guide

**Script:** `tools/soak/audit_artifacts.py`  
**Purpose:** Comprehensive post-soak analysis and readiness report  
**Status:** âœ… Ready for use

---

## ðŸŽ¯ What It Does

Analyzes artifacts from `artifacts/soak/latest/` and produces:

1. **Console Report** â€” Real-time KPI summary with readiness verdict
2. **Markdown Report** â€” `POST_SOAK_AUDIT_SUMMARY.md` with trends and recommendations
3. **JSON Summary** â€” `POST_SOAK_AUDIT_SUMMARY.json` with all computed metrics
4. **CSV Table** â€” `POST_SOAK_ITER_TABLE.csv` with per-iteration data

---

## ðŸ“¦ Input Files (Expected)

```
artifacts/soak/latest/
â”œâ”€â”€ ITER_SUMMARY_1.json         # Required (16-24 files)
â”œâ”€â”€ ITER_SUMMARY_2.json
â”œâ”€â”€ ...
â”œâ”€â”€ TUNING_REPORT.json          # Optional
â”œâ”€â”€ DELTA_VERIFY_REPORT.md      # Optional
â””â”€â”€ reports/
    â””â”€â”€ analysis/
        â”œâ”€â”€ POST_SOAK_SNAPSHOT.json  # Optional (will derive if missing)
        â””â”€â”€ warmup_metrics.prom      # Optional
```

**Minimum Required:**
- At least **16 ITER_SUMMARY_*.json** files
- Ideally **24** for full 24-iteration soak

**Optional (but recommended):**
- `POST_SOAK_SNAPSHOT.json` â€” Pre-computed KPI aggregates
- `TUNING_REPORT.json` â€” Auto-tuning deltas and guard skips
- `DELTA_VERIFY_REPORT.md` â€” Delta application verification
- `warmup_metrics.prom` â€” Prometheus warmup metrics

---

## ðŸš€ Usage

### **Basic (from repo root):**

```bash
python -m tools.soak.audit_artifacts
```

### **Custom base directory:**

```bash
python -m tools.soak.audit_artifacts --base path/to/soak/artifacts
```

### **Example output:**

```
==============================================================================
SOAK ARTIFACT AUDIT: artifacts/soak/latest
==============================================================================

[1/11] Verifying folder structure...
âœ“ Base directory exists: /workspace/artifacts/soak/latest
  Files found: 87 (showing first 120)
    - ITER_SUMMARY_1.json: 12.3 KB
    - ITER_SUMMARY_2.json: 12.5 KB
    ...

Key files:
  âœ“ POST_SOAK_SNAPSHOT.json
  âœ“ TUNING_REPORT.json
  âœ“ DELTA_VERIFY_REPORT.md
  âœ— (missing) warmup_metrics.prom

[2/11] Loading ITER_SUMMARY files...
âœ“ Found 24 ITER_SUMMARY files
âœ“ Loaded 24 iterations

[3/11] Computing trend statistics...
Trend Statistics:
Metric               Window     Min      Max   Median
------------------------------------------------------------
net_bps              overall    2.34     3.89     3.12
net_bps              steady     2.67     3.89     3.15
net_bps              last8      2.89     3.65     3.18
...

[5/11] Readiness Gate Check (last-8 window)...
Metric               Target          Actual     Status
------------------------------------------------------------
maker_taker_ratio    >= 0.83          0.871     âœ“ PASS
net_bps              >= 2.9           3.180     âœ“ PASS
p95_latency_ms       <= 330         312.000     âœ“ PASS
risk_ratio           <= 0.40          0.352     âœ“ PASS

âœ… READINESS: OK (all KPIs within thresholds)

[9/11] Generating recommendations...
Recommendations:
  âœ“ All KPIs within target ranges; no immediate action needed

[10/11] Creating Markdown report...
âœ“ Saved CSV: POST_SOAK_ITER_TABLE.csv
âœ“ Saved Markdown: POST_SOAK_AUDIT_SUMMARY.md
âœ“ Saved JSON: POST_SOAK_AUDIT_SUMMARY.json

==============================================================================
ðŸŽ¯ FINAL VERDICT: READINESS: OK
==============================================================================
```

---

## ðŸ“Š Output Files

### **1. POST_SOAK_AUDIT_SUMMARY.md**

Comprehensive markdown report with:
- File inventory (present/missing)
- Readiness gate table (target vs actual)
- Trend statistics (overall / STEADY / last-8)
- Tuning & delta verification summary
- Actionable recommendations

**Example:**

```markdown
# Post-Soak Audit Summary

**Generated:** 2025-10-19 12:34:56 UTC  
**Iterations:** 24 (max iter: 24)  
**STEADY Window:** iter >= 7  
**Last-8 Window:** iter >= 17  

## Readiness Gate (last-8 window)

| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| maker_taker_ratio | >= 0.83 | 0.871 | âœ“ PASS |
| net_bps | >= 2.9 | 3.180 | âœ“ PASS |
| p95_latency_ms | <= 330 | 312.000 | âœ“ PASS |
| risk_ratio | <= 0.40 | 0.352 | âœ“ PASS |

**Verdict:** âœ… READINESS: OK

## Recommendations

âœ“ All KPIs within target ranges; no immediate action needed
```

### **2. POST_SOAK_AUDIT_SUMMARY.json**

Machine-readable JSON with all computed stats:

```json
{
  "timestamp": "2025-10-19 12:34:56 UTC",
  "iterations": 24,
  "snapshot_kpis": {
    "maker_taker_ratio": 0.871,
    "net_bps": 3.18,
    "p95_latency_ms": 312.0,
    "risk_ratio": 0.352
  },
  "readiness": {
    "pass": true,
    "failures": []
  },
  "trend_stats": {
    "net_bps": {
      "overall": {"min": 2.34, "max": 3.89, "median": 3.12},
      "steady": {"min": 2.67, "max": 3.89, "median": 3.15},
      "last8": {"min": 2.89, "max": 3.65, "median": 3.18}
    },
    ...
  }
}
```

### **3. POST_SOAK_ITER_TABLE.csv**

Per-iteration KPI table (for Excel/pandas):

```csv
iter,net_bps,risk_ratio,slippage_p95,adverse_p95,latency_p95_ms,maker_taker_ratio
1,2.45,0.38,1.2,2.1,325,0.82
2,2.67,0.36,1.1,2.0,318,0.84
...
24,3.21,0.35,0.9,1.8,310,0.89
```

---

## ðŸŽ¯ Readiness Thresholds

Default thresholds (as of 2025-10-19):

| Metric | Threshold | Window |
|--------|-----------|--------|
| **maker_taker_ratio** | â‰¥ 0.83 | last-8 |
| **net_bps** | â‰¥ 2.9 | last-8 |
| **p95_latency_ms** | â‰¤ 330 ms | last-8 |
| **risk_ratio** | â‰¤ 0.40 | last-8 |

**Window definitions:**
- **overall:** All iterations (1..N)
- **STEADY:** Iterations >= 7 (warm-up complete)
- **last-8:** Highest 8 iterations (e.g., 17..24)

---

## ðŸ” What Gets Analyzed

### **1. File Inventory**
- Checks presence of key files
- Lists first 120 files with sizes
- Reports missing optional files

### **2. ITER_SUMMARY Files**
- Loads all `ITER_SUMMARY_*.json`
- Extracts KPIs with robust fallbacks:
  - `net_bps` (multiple field names supported)
  - `risk_ratio` (handles `risk_percent` conversion)
  - `maker_taker_ratio` (can compute from maker/taker counts)
  - `p95_latency_ms` (multiple field names)
  - `slippage_p95`, `adverse_p95`
- Builds DataFrame for trend analysis

### **3. Trend Statistics**
- Computes min/max/median for each KPI
- Three windows: overall, STEADY (iter >= 7), last-8
- Identifies regression or improvement

### **4. POST_SOAK_SNAPSHOT**
- Loads existing snapshot (if present)
- Derives from last-8 window (if missing)
- Extracts 4 readiness KPIs

### **5. Readiness Gate**
- Validates last-8 KPIs against thresholds
- Clear PASS/FAIL per metric
- Overall verdict: OK or HOLD

### **6. TUNING_REPORT**
- Aggregates guard skip reasons
- Counts proposed vs applied deltas
- Top 5 skip reasons histogram

### **7. DELTA_VERIFY_REPORT**
- Parses "Full applications: X/Y (Z%)"
- Reports delta application success rate

### **8. warmup_metrics.prom**
- Extracts `exporter_error` count
- Parses `guard_triggers_total{type="..."}`
- Summary of guard activity

### **9. Recommendations**
- Actionable suggestions based on KPI failures
- Specific parameter nudges for maker/taker imbalance
- Considers STEADY adverse_p95 for risk adjustments

---

## ðŸ› ï¸ Advanced Usage

### **Check if artifacts are ready for audit:**

```bash
# Ensure at least 16 ITER_SUMMARY files exist
ls -1 artifacts/soak/latest/ITER_SUMMARY_*.json | wc -l
# Output: 24 (good!)
```

### **Run audit and save console output:**

```bash
python -m tools.soak.audit_artifacts 2>&1 | tee audit_output.log
```

### **Parse JSON summary for CI:**

```python
import json
from pathlib import Path

summary = json.loads(Path("artifacts/soak/latest/reports/analysis/POST_SOAK_AUDIT_SUMMARY.json").read_text())

if summary["readiness"]["pass"]:
    print("âœ… READY FOR RELEASE")
    exit(0)
else:
    print("âŒ NOT READY:")
    for failure in summary["readiness"]["failures"]:
        print(f"  - {failure}")
    exit(1)
```

### **Load CSV in pandas:**

```python
import pandas as pd

df = pd.read_csv("artifacts/soak/latest/reports/analysis/POST_SOAK_ITER_TABLE.csv")
print(df[["iter", "net_bps", "risk_ratio", "maker_taker_ratio"]].describe())
```

---

## ðŸ“‹ Typical Workflow

### **After 24-iteration soak:**

```bash
# 1. Check files exist
ls artifacts/soak/latest/ITER_SUMMARY_*.json

# 2. Run audit
python -m tools.soak.audit_artifacts

# 3. Review markdown report
cat artifacts/soak/latest/reports/analysis/POST_SOAK_AUDIT_SUMMARY.md

# 4. If HOLD: review recommendations
grep "Recommendations" -A 20 artifacts/soak/latest/reports/analysis/POST_SOAK_AUDIT_SUMMARY.md

# 5. Adjust parameters and re-run soak (if needed)
```

---

## ðŸ”§ Customization

### **Change thresholds:**

Edit `READINESS_THRESHOLDS` dict in `audit_artifacts.py`:

```python
READINESS_THRESHOLDS = {
    "maker_taker_ratio": (">=", 0.85),  # Stricter
    "net_bps": (">=", 3.0),             # Higher edge
    "p95_latency_ms": ("<=", 300),      # Tighter latency
    "risk_ratio": ("<=", 0.35),         # Lower risk
}
```

### **Change STEADY window:**

```python
STEADY_START_ITER = 5  # Earlier STEADY (default: 7)
```

---

## ðŸš¨ Troubleshooting

### **"No ITER_SUMMARY data loaded"**

**Cause:** Missing or malformed ITER_SUMMARY files  
**Fix:**
```bash
# Check if files exist
ls artifacts/soak/latest/ITER_SUMMARY_*.json

# Validate JSON
python -m json.tool artifacts/soak/latest/ITER_SUMMARY_1.json
```

### **"Only X ITER_SUMMARY files found (expected >= 16)"**

**Cause:** Incomplete soak run  
**Fix:** Re-run soak with `--iterations 24`

### **"POST_SOAK_SNAPSHOT.json not found; deriving..."**

**Not an error!** Script will compute KPIs from ITER_SUMMARY files.  
To generate snapshot explicitly:
```bash
python -m tools.soak.build_reports \
  --src artifacts/soak/latest \
  --out artifacts/soak/latest/reports/analysis \
  --last-n 8
```

### **"pandas not available; using manual tabulation"**

**Not critical.** Script works without pandas (slightly slower).  
To install pandas:
```bash
pip install pandas
```

---

## ðŸ”§ Strict Mode / CI Integration

The `--fail-on-hold` flag makes the audit exit with code 1 if readiness is **HOLD**.

### **Example: Strict mode (for nightly CI)**

```bash
python -m tools.soak.audit_artifacts --base artifacts/soak/latest --fail-on-hold
```

**Exit codes:**
- `0`: Readiness is **OK** (all KPIs pass)
- `1`: Readiness is **HOLD** (one or more KPIs failed) **AND** `--fail-on-hold` is set

**Usage in CI workflows:**

```yaml
- name: Post-Soak Audit (strict)
  run: |
    python -m tools.soak.audit_artifacts \
      --base artifacts/soak/latest \
      --fail-on-hold
```

**Output:**

```
ðŸŽ¯ FINAL VERDICT: READINESS: HOLD (2 KPI(s) failed)
[EXIT] fail-on-hold: True, verdict: HOLD, exit_code=1
```

**Makefile shortcut:**

```bash
make soak-audit-ci  # Runs with --fail-on-hold
```

---

## ðŸ’¬ PR Summary

The `emit_pr_summary.py` script generates a short markdown summary for posting to PR comments.

### **Usage:**

```bash
python -m tools.soak.ci_gates.emit_pr_summary \
  artifacts/soak/latest/reports/analysis/POST_SOAK_AUDIT_SUMMARY.json
```

**Output:**

```markdown
### Post-Soak Readiness (last-8 window)

âœ… READINESS: OK

- maker_taker_ratio: **0.871** (â‰¥ 0.83)
- net_bps: **3.180** (â‰¥ 2.9)
- p95_latency_ms: **312** (â‰¤ 330)
- risk_ratio: **0.352** (â‰¤ 0.40)
```

### **Integration in GitHub Actions:**

```yaml
- name: Build PR summary
  if: github.event.pull_request.number
  run: |
    python -m tools.soak.ci_gates.emit_pr_summary > pr_summary.md

- name: Comment to PR
  if: github.event.pull_request.number
  uses: actions/github-script@v7
  with:
    github-token: ${{ secrets.GITHUB_TOKEN }}
    script: |
      const fs = require('fs');
      const body = fs.readFileSync('pr_summary.md', 'utf8');
      await github.rest.issues.createComment({
        owner: context.repo.owner,
        repo: context.repo.repo,
        issue_number: context.payload.pull_request.number,
        body
      });
```

---

## ðŸ”„ Run Comparison

The `compare_runs.py` tool compares two soak runs by their last-8 KPI snapshots.

### **Usage:**

```bash
python -m tools.soak.compare_runs \
  --a artifacts/soak/baseline \
  --b artifacts/soak/latest
```

**Output (CSV):**

```
KPI,A,B,B-A (note: for latency smaller is better)
maker_taker_ratio,0.850,0.871,0.021
net_bps,3.050,3.180,0.130
p95_latency_ms,325.000,312.000,-13.000
risk_ratio,0.360,0.352,-0.008
```

**Interpretation:**
- **B-A > 0**: B is higher than A
- **B-A < 0**: B is lower than A
- For `p95_latency_ms`: negative delta is **good** (lower latency)
- For `risk_ratio`: negative delta is **good** (lower risk)

**Makefile shortcut:**

```bash
make soak-compare  # Compares run_A vs latest
```

**Note:** Both runs must have been analyzed with `audit_artifacts` first.

---

## ðŸ“Š Plots

The `--plots` flag generates PNG graphs of KPI trends (requires `matplotlib`).

### **Usage:**

```bash
python -m tools.soak.audit_artifacts --base artifacts/soak/latest --plots
```

**Output files:**

```
artifacts/soak/latest/reports/analysis/plots/
â”œâ”€â”€ net_bps.png
â”œâ”€â”€ risk_ratio.png
â”œâ”€â”€ latency_p95_ms.png
â””â”€â”€ maker_taker_ratio.png
```

**Features:**
- Line plots with markers
- Threshold lines (from readiness gate)
- Grid for easy reading
- 10x6 inch size, 100 DPI

**If matplotlib not installed:**

```
âš  WARNING: matplotlib not available; skipping plots
```

**To install matplotlib:**

```bash
pip install matplotlib
```

---

## ðŸ“š Related Tools

| Tool | Purpose |
|------|---------|
| `tools.soak.run` | Run soak test (generates artifacts) |
| `tools.soak.build_reports` | Build POST_SOAK_SNAPSHOT.json |
| `tools.soak.verify_deltas_applied` | Verify delta application |
| `tools.soak.export_warmup_metrics` | Export Prometheus metrics |
| `tools.soak.ci_gates.readiness_gate` | CI readiness validation |
| `tools.soak.audit_artifacts` | **This tool** â€” comprehensive audit |

---

## ðŸŽ‰ Example Success Output

```
==============================================================================
ðŸŽ¯ FINAL VERDICT: READINESS: OK
==============================================================================

ðŸ“„ Full report: artifacts/soak/latest/reports/analysis/POST_SOAK_AUDIT_SUMMARY.md
ðŸ“Š JSON summary: artifacts/soak/latest/reports/analysis/POST_SOAK_AUDIT_SUMMARY.json
ðŸ“ˆ CSV table: artifacts/soak/latest/reports/analysis/POST_SOAK_ITER_TABLE.csv

All KPIs within thresholds:
  âœ“ maker_taker_ratio: 0.871 >= 0.83
  âœ“ net_bps: 3.18 >= 2.9
  âœ“ p95_latency_ms: 312 <= 330
  âœ“ risk_ratio: 0.352 <= 0.40

âœ… READY FOR RELEASE
```

---

**Last Updated:** 2025-10-19  
**Script Version:** 1.1.0  
**Python:** 3.11+  
**Dependencies:** stdlib only (pandas optional, matplotlib optional)

