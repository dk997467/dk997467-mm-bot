#!/usr/bin/env python3
"""
Demo script for E2 Finish + F1 Prep integration test.
"""

import json
import tempfile
from pathlib import Path
from datetime import datetime, timezone

from src.research.calibrate import _validate_go_no_go_block
from src.deploy.thresholds import GateThresholds, validate_thresholds


def create_mock_report_json(out_dir: Path) -> None:
    """Create a complete mock E2 report.json for testing."""
    report_data = {
        "metadata": {
            "symbol": "BTCUSDT",
            "generated_at_utc": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%S.%fZ"),
            "seed": 42,
            "round_dp": 6,
            "weights": {"KS_queue": 1.0, "KS_bins": 1.0, "L_hit": 1.0, "L_maker": 0.5, "L_reg": 1.0},
            "w4_effective": 0.0,
            "cache_hits": 5,
            "cache_misses": 15
        },
        "live_distributions": {
            "queue_wait_cdf_ms": [
                {"p": 0.25, "v": 120.0},
                {"p": 0.5, "v": 180.0},
                {"p": 0.75, "v": 240.0},
                {"p": 0.9, "v": 300.0}
            ],
            "hit_rate_by_bin": {
                "0": {"count": 200, "fills": 60},
                "5": {"count": 180, "fills": 45},
                "10": {"count": 160, "fills": 32}
            },
            "live_hit": 0.30,
            "live_maker": None  # Test missing maker case
        },
        "calibration_params": {
            "latency_ms_mean": 100.0,
            "latency_ms_std": 10.0,
            "amend_latency_ms": 50.0,
            "cancel_latency_ms": 30.0,
            "toxic_sweep_prob": 0.05,
            "extra_slippage_bps": 2.5
        },
        "loss_after": {
            "KS_queue": 0.234567,
            "KS_bins": 0.156789,
            "L_hit": 0.045123,
            "L_maker": 0.0,  # Should be 0 when live_maker is None
            "L_reg": 0.001234,
            "TotalLoss": 0.389456
        },
        "loss_before": {
            "KS_queue": 0.345678,
            "KS_bins": 0.187654,
            "L_hit": 0.067890,
            "L_maker": 0.012345,
            "L_reg": 0.001234,
            "TotalLoss": 0.456789
        },
        "go_no_go": {
            "ks_queue_after": round(0.234567, 6),
            "ks_bins_after": round(0.156789, 6),
            "w4_effective": 0.0,
            "sim_live_divergence": round(0.5 * (0.234567 + 0.156789), 6),
            "loss_before": round(0.456789, 6),
            "loss_after": round(0.389456, 6),
            "loss_regressed": False
        }
    }
    
    # Write report.json
    report_path = out_dir / "report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, sort_keys=True, ensure_ascii=False, indent=2)
    
    # Write calibration.json
    calibration_path = out_dir / "calibration.json"
    with open(calibration_path, 'w', encoding='utf-8') as f:
        json.dump(report_data["calibration_params"], f, sort_keys=True, indent=2)
    
    # Write calibration.json.ref (identical for determinism test)
    calibration_ref_path = out_dir / "calibration.json.ref"
    with open(calibration_ref_path, 'w', encoding='utf-8') as f:
        json.dump(report_data["calibration_params"], f, sort_keys=True, indent=2)
    
    print(f"Created mock E2 report at: {out_dir}")


def demo_e2_f1_integration():
    """Demonstrate E2 finish + F1 prep integration."""
    print("üõ°Ô∏è E2 Finish + F1 Prep Integration Demo")
    print("=" * 45)
    
    # 1. Test GateThresholds
    print("\n1Ô∏è‚É£ Testing F1 GateThresholds:")
    thresholds = GateThresholds()
    print(f"   Default max_sim_live_divergence: {thresholds.max_sim_live_divergence}")
    print(f"   Default min_hit_rate: {thresholds.min_hit_rate}")
    print(f"   Default max_report_age_hours: {thresholds.max_report_age_hours}")
    
    errors = validate_thresholds(thresholds)
    if errors:
        print(f"   Validation errors: {errors}")
    else:
        print("   ‚úÖ Default thresholds are valid")
    
    # 2. Test go_no_go validation
    print("\n2Ô∏è‚É£ Testing go_no_go validation:")
    valid_go_no_go = {
        "ks_queue_after": 0.234567,
        "ks_bins_after": 0.156789,
        "w4_effective": 0.0,
        "sim_live_divergence": 0.195678,
        "loss_before": 0.456789,
        "loss_after": 0.389456,
        "loss_regressed": False
    }
    
    errors = _validate_go_no_go_block(valid_go_no_go, round_dp=6)
    if errors:
        print(f"   Validation errors: {errors}")
    else:
        print("   ‚úÖ Valid go_no_go block passes validation")
    
    # Test invalid case
    invalid_go_no_go = valid_go_no_go.copy()
    del invalid_go_no_go["sim_live_divergence"]
    
    errors = _validate_go_no_go_block(invalid_go_no_go, round_dp=6)
    if errors:
        print(f"   ‚úÖ Invalid block correctly fails: {errors[0]}")
    
    # 3. Test F1 gate logic
    print("\n3Ô∏è‚É£ Testing F1 gate logic:")
    divergence = valid_go_no_go["sim_live_divergence"]
    
    if divergence > thresholds.max_sim_live_divergence:
        gate_result = "REJECT"
        reason = f"High divergence: {divergence:.3f} > {thresholds.max_sim_live_divergence}"
    elif valid_go_no_go["loss_regressed"]:
        gate_result = "WARNING"
        reason = "Optimization regressed"
    else:
        gate_result = "PROCEED"
        reason = "All checks passed"
    
    print(f"   F1 gate result: {gate_result}")
    print(f"   Reason: {reason}")
    
    # 4. Create and test complete mock setup
    print("\n4Ô∏è‚É£ Testing complete E2 report structure:")
    with tempfile.TemporaryDirectory() as temp_dir:
        out_dir = Path(temp_dir) / "artifacts"
        out_dir.mkdir()
        
        create_mock_report_json(out_dir)
        
        # Load and validate the complete report
        report_path = out_dir / "report.json"
        with open(report_path, 'r', encoding='utf-8') as f:
            full_report = json.load(f)
        
        go_no_go = full_report["go_no_go"]
        print(f"   Created go_no_go with {len(go_no_go)} fields")
        
        # Validate structure
        validation_errors = _validate_go_no_go_block(go_no_go, 6)
        if validation_errors:
            print(f"   ‚ùå Validation failed: {validation_errors}")
        else:
            print("   ‚úÖ Complete report structure is valid")
        
        # Check w4_effective logic
        live_maker = full_report["live_distributions"]["live_maker"]
        w4_eff = go_no_go["w4_effective"]
        l_maker = full_report["loss_after"]["L_maker"]
        
        if live_maker is None:
            if w4_eff == 0.0 and l_maker == 0.0:
                print("   ‚úÖ w4_effective=0 and L_maker=0 when live_maker is None")
            else:
                print(f"   ‚ùå Expected w4_eff=0, L_maker=0, got w4_eff={w4_eff}, L_maker={l_maker}")
        
        # Check sim_live_divergence calculation
        expected_div = 0.5 * (go_no_go["ks_queue_after"] + go_no_go["ks_bins_after"])
        actual_div = go_no_go["sim_live_divergence"]
        
        if abs(actual_div - expected_div) < 1e-9:
            print(f"   ‚úÖ sim_live_divergence correctly calculated: {actual_div:.6f}")
        else:
            print(f"   ‚ùå Divergence mismatch: expected {expected_div:.6f}, got {actual_div:.6f}")
    
    print("\n5Ô∏è‚É£ F1 Integration Summary:")
    print(f"   ‚Ä¢ GateThresholds: ‚úÖ Loaded and validated")
    print(f"   ‚Ä¢ go_no_go validation: ‚úÖ Working correctly")
    print(f"   ‚Ä¢ F1 gate logic: ‚úÖ {gate_result} decision")
    print(f"   ‚Ä¢ E2 report structure: ‚úÖ Complete and valid")
    print(f"   ‚Ä¢ w4_effective handling: ‚úÖ Correct for missing live_maker")
    print(f"   ‚Ä¢ sim_live_divergence: ‚úÖ Correctly calculated")
    
    return True


if __name__ == "__main__":
    success = demo_e2_f1_integration()
    if success:
        print(f"\nüéâ E2 Finish + F1 Prep integration demo completed successfully!")
    else:
        print(f"\n‚ùå Integration demo failed!")
