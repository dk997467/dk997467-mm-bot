# üéØ MM Rebate Bot: Action Items –∏–∑ –∞—É–¥–∏—Ç–∞

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2025-10-01  
**–°—Ç–∞—Ç—É—Å:** –í —Ä–∞–±–æ—Ç–µ  

---

## üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï (–∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ)

### SEC-001: API –∫–ª—é—á–∏ –≤ Docker Secrets
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P0 (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å  
**–í—Ä–µ–º—è:** 2 —á–∞—Å–∞  
**–§–∞–π–ª—ã:** `docker-compose.yml`, `src/common/config.py`

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:**
```yaml
# docker-compose.yml:9-17
environment:
  - BYBIT_API_KEY=${BYBIT_API_KEY}  # ‚ùå Plain text
  - BYBIT_API_SECRET=${BYBIT_API_SECRET}
```

**–¢—Ä–µ–±—É–µ–º–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ:**
```yaml
# docker-compose.yml
services:
  market-maker-bot:
    secrets:
      - bybit_api_key
      - bybit_api_secret
    environment:
      - BYBIT_API_KEY_FILE=/run/secrets/bybit_api_key
      - BYBIT_API_SECRET_FILE=/run/secrets/bybit_api_secret

secrets:
  bybit_api_key:
    external: true
  bybit_api_secret:
    external: true
```

**–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–¥–µ:**
```python
# src/common/config.py - –¥–æ–±–∞–≤–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é
def _load_secret(env_var: str) -> str:
    """Load secret from file if _FILE suffix exists, else from env."""
    file_var = f"{env_var}_FILE"
    if file_var in os.environ:
        with open(os.environ[file_var], 'r') as f:
            return f.read().strip()
    return os.getenv(env_var, '')

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
config.bybit.api_key = _load_secret('BYBIT_API_KEY')
config.bybit.api_secret = _load_secret('BYBIT_API_SECRET')
```

**–ö–æ–º–∞–Ω–¥—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ–∫—Ä–µ—Ç–æ–≤:**
```bash
echo "your_api_key" | docker secret create bybit_api_key -
echo "your_api_secret" | docker secret create bybit_api_secret -
```

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] Docker Compose –∏—Å–ø–æ–ª—å–∑—É–µ—Ç secrets
- [ ] Config.py —á–∏—Ç–∞–µ—Ç –∏–∑ `/run/secrets/`
- [ ] Fallback –Ω–∞ env vars –¥–ª—è dev-—Ä–µ–∂–∏–º–∞
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç —Å mock —Å–µ–∫—Ä–µ—Ç–∞–º–∏

---

### SOAK-001: –£—Ç–µ—á–∫–∞ –ø–∞–º—è—Ç–∏ –≤ lint_ascii_logs.py
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P0 (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Soak-—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å  
**–í—Ä–µ–º—è:** 1 —á–∞—Å  
**–§–∞–π–ª:** `tools/ci/lint_ascii_logs.py:22-25`

**–ü—Ä–æ–±–ª–µ–º–∞:**
```python
with open(path, 'r', encoding='utf-8') as f:
    content = f.read()  # ‚ùå –ß–∏—Ç–∞–µ—Ç –≤–µ—Å—å —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç—å!
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
def check_file_ascii(path: str) -> List[Tuple[int, str]]:
    """Check file for non-ASCII content line-by-line."""
    violations = []
    max_line_length = 10000  # Safety limit
    
    with open(path, 'r', encoding='utf-8', errors='replace') as f:
        for line_no, line in enumerate(f, 1):
            # Safety: skip extremely long lines
            if len(line) > max_line_length:
                violations.append((line_no, 'line too long (>10KB)'))
                continue
            
            # Check only print() lines to reduce false positives
            if 'print(' in line:
                try:
                    line.encode('ascii')
                except UnicodeEncodeError as e:
                    snippet = line[max(0, e.start-20):e.end+20]
                    violations.append((line_no, f'non-ascii: {snippet!r}'))
    
    return violations

def main() -> int:
    violations = []
    for root, _, files in os.walk('.'):
        if any(seg in root for seg in ('/venv', '\\venv', '/dist', '\\dist', '/.git')):
            continue
        for fn in files:
            path = os.path.join(root, fn).lstrip('./')
            if not is_text_file(path):
                continue
            try:
                file_violations = check_file_ascii(path)
                violations.extend((path, ln, msg) for ln, msg in file_violations)
            except Exception as e:
                print(f'[WARN] Failed to check {path}: {e}', file=sys.stderr)
    
    if violations:
        for p, ln, msg in violations:
            print(f'ASCII_LINT {p}:{ln}: {msg}')
        return 2
    print('ASCII_LINT OK')
    return 0
```

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] –§–∞–π–ª—ã —á–∏—Ç–∞—é—Ç—Å—è –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
- [ ] –ù–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞ –≤ –ø–∞–º—è—Ç—å
- [ ] –î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞—â–∏—Ç–∞ –æ—Ç –æ–≥—Ä–æ–º–Ω—ã—Ö —Å—Ç—Ä–æ–∫
- [ ] –¢–µ—Å—Ç –Ω–∞ —Ñ–∞–π–ª–µ 100MB –ø—Ä–æ—Ö–æ–¥–∏—Ç –±–µ–∑ OOM

---

### SOAK-002: –†–æ—Ç–∞—Ü–∏—è –ª–æ–≥–æ–≤ –≤ full_stack_validate.py
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P0 (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Soak-—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å  
**–í—Ä–µ–º—è:** 1 —á–∞—Å  
**–§–∞–π–ª:** `tools/ci/full_stack_validate.py:80-86`

**–ü—Ä–æ–±–ª–µ–º–∞:** –í 72-—á–∞—Å–æ–≤–æ–º soak-–ø—Ä–æ–≥–æ–Ω–µ —Å–æ–∑–¥–∞–µ—Ç—Å—è 500+ —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤.

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –í –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
MAX_LOG_FILES_PER_STEP = 5
MAX_TOTAL_LOG_SIZE_MB = 500

def _cleanup_old_logs(label: str) -> None:
    """Keep only last N log files per step to prevent disk bloat."""
    # Get all log files for this step
    out_logs = sorted(
        CI_ARTIFACTS_DIR.glob(f"{label}.*.out.log"),
        key=lambda p: p.stat().st_mtime
    )
    err_logs = sorted(
        CI_ARTIFACTS_DIR.glob(f"{label}.*.err.log"),
        key=lambda p: p.stat().st_mtime
    )
    
    # Delete oldest files beyond limit
    for old_file in out_logs[:-MAX_LOG_FILES_PER_STEP]:
        try:
            old_file.unlink()
        except Exception:
            pass
    
    for old_file in err_logs[:-MAX_LOG_FILES_PER_STEP]:
        try:
            old_file.unlink()
        except Exception:
            pass

def _check_disk_space() -> None:
    """Alert if CI artifacts directory exceeds size limit."""
    total_size_mb = sum(
        f.stat().st_size for f in CI_ARTIFACTS_DIR.rglob('*') if f.is_file()
    ) / (1024 * 1024)
    
    if total_size_mb > MAX_TOTAL_LOG_SIZE_MB:
        print(f"[WARN] CI artifacts size: {total_size_mb:.1f} MB (limit: {MAX_TOTAL_LOG_SIZE_MB} MB)", 
              file=sys.stderr)
        # Aggressive cleanup: keep only last 2 per step
        for label in ['ascii_logs', 'json_writer', 'metrics_labels', 'tests_whitelist']:
            logs = sorted(CI_ARTIFACTS_DIR.glob(f"{label}.*.out.log"), key=lambda p: p.stat().st_mtime)
            for old_file in logs[:-2]:
                old_file.unlink(missing_ok=True)
                old_file.with_suffix('.err.log').unlink(missing_ok=True)

def run_step(label: str, cmd: List[str]) -> Dict[str, Any]:
    # –í –Ω–∞—á–∞–ª–µ —Ñ—É–Ω–∫—Ü–∏–∏:
    _cleanup_old_logs(label)
    _check_disk_space()
    
    # ... rest of existing code ...
```

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] –•—Ä–∞–Ω–∏—Ç—Å—è max 5 –ª–æ–≥–æ–≤ –Ω–∞ –∫–∞–∂–¥—ã–π step
- [ ] Alert –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ 500MB –≤ `artifacts/ci/`
- [ ] Aggressive cleanup —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- [ ] 72-—á–∞—Å–æ–≤–æ–π —Ç–µ—Å—Ç –Ω–µ –∑–∞–±–∏–≤–∞–µ—Ç –¥–∏—Å–∫

---

### NET-001: Exponential backoff –≤ WebSocket reconnect
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P0 (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å  
**–í—Ä–µ–º—è:** 1 —á–∞—Å  
**–§–∞–π–ª:** `src/connectors/bybit_ws.py:483-512`

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ—Ç –∑–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è.

**–†–µ—à–µ–Ω–∏–µ:**
```python
import random

async def _handle_public_disconnect(self):
    """Handle public WebSocket disconnection with exponential backoff."""
    self.public_connected = False
    
    if self.public_ws:
        try:
            await self.public_ws.close()
        except Exception:
            pass
        self.public_ws = None
    
    self.reconnect_attempts += 1
    
    if self.reconnect_attempts > self.max_reconnect_attempts:
        logger.error(
            "Max reconnection attempts reached for public WebSocket",
            attempts=self.reconnect_attempts,
            max_attempts=self.max_reconnect_attempts
        )
        # Notify monitoring system
        if self.metrics:
            self.metrics.ws_reconnect_exhausted_total.labels(ws_type="public").inc()
        return
    
    # Exponential backoff: 1s, 2s, 4s, 8s, 16s, 32s, max 60s
    backoff_base = 2 ** (self.reconnect_attempts - 1)
    backoff_sec = min(backoff_base, 60)
    
    # Add jitter (¬±30%) to prevent thundering herd
    jitter = random.uniform(-0.3 * backoff_sec, 0.3 * backoff_sec)
    sleep_sec = max(1.0, backoff_sec + jitter)
    
    logger.info(
        "Public WebSocket disconnected, will retry",
        attempt=self.reconnect_attempts,
        max_attempts=self.max_reconnect_attempts,
        backoff_sec=sleep_sec
    )
    
    await asyncio.sleep(sleep_sec)
    
    # Attempt reconnection
    try:
        await self._connect_public()
        self.reconnect_attempts = 0  # Reset on successful reconnect
        logger.info("Public WebSocket reconnected successfully")
    except Exception as e:
        logger.error("Failed to reconnect public WebSocket", error=str(e))
        # Will retry on next disconnect event

# –¢–æ –∂–µ —Å–∞–º–æ–µ –¥–ª—è _handle_private_disconnect()
```

**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏:**
```python
# src/metrics/exporter.py
self.ws_reconnect_attempts_total = Counter(
    'ws_reconnect_attempts_total',
    'WebSocket reconnection attempts',
    ['ws_type']
)
self.ws_reconnect_exhausted_total = Counter(
    'ws_reconnect_exhausted_total',
    'WebSocket reconnection attempts exhausted',
    ['ws_type']
)
self.ws_reconnect_backoff_seconds = Histogram(
    'ws_reconnect_backoff_seconds',
    'WebSocket reconnection backoff duration',
    ['ws_type'],
    buckets=(1, 2, 4, 8, 16, 32, 60)
)
```

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] Exponential backoff —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω (1s ‚Üí 60s)
- [ ] Jitter –¥–æ–±–∞–≤–ª–µ–Ω (¬±30%)
- [ ] –ú–µ—Ç—Ä–∏–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è
- [ ] –¢–µ—Å—Ç: —Å–∏–º—É–ª—è—Ü–∏—è 10 —Ä–∞–∑—Ä—ã–≤–æ–≤, –Ω–µ—Ç flood –Ω–∞ –±–∏—Ä–∂—É

---

### SYS-001: Graceful shutdown —Å –æ—á–∏—Å—Ç–∫–æ–π —Ä–µ—Å—É—Ä—Å–æ–≤
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P0 (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å  
**–í—Ä–µ–º—è:** 1 —á–∞—Å  
**–§–∞–π–ª:** `cli/run_bot.py` (–º–µ—Ç–æ–¥ `stop()`)

**–†–µ—à–µ–Ω–∏–µ:** –°–æ–∑–¥–∞—Ç—å —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π shutdown handler:

```python
# cli/run_bot.py
import signal
import asyncio
from typing import Optional, List

class MarketMakerBot:
    def __init__(self, ...):
        # ... existing init ...
        self._shutdown_event = asyncio.Event()
        self._background_tasks: List[asyncio.Task] = []
    
    def register_background_task(self, task: asyncio.Task, name: str) -> None:
        """Register background task for cleanup on shutdown."""
        task.set_name(name)
        self._background_tasks.append(task)
    
    async def stop(self, timeout: float = 30.0) -> None:
        """Graceful shutdown with resource cleanup."""
        logger.info("Initiating graceful shutdown...")
        self.running = False
        self._shutdown_event.set()
        
        start_time = time.time()
        
        # 1. Cancel all background tasks
        logger.info(f"Cancelling {len(self._background_tasks)} background tasks...")
        for task in self._background_tasks:
            if not task.done():
                task.cancel()
        
        # Wait for cancellation with timeout
        if self._background_tasks:
            try:
                await asyncio.wait_for(
                    asyncio.gather(*self._background_tasks, return_exceptions=True),
                    timeout=10.0
                )
            except asyncio.TimeoutError:
                logger.warning("Some background tasks did not finish within timeout")
        
        # 2. Stop strategy (cancel orders)
        if self.strategy:
            try:
                logger.info("Stopping strategy and cancelling active orders...")
                await asyncio.wait_for(self.strategy.stop(), timeout=5.0)
            except asyncio.TimeoutError:
                logger.error("Strategy stop timed out")
        
        # 3. Close WebSocket connections
        if self.ws_connector:
            try:
                logger.info("Closing WebSocket connections...")
                await asyncio.wait_for(self.ws_connector.disconnect(), timeout=5.0)
            except asyncio.TimeoutError:
                logger.error("WebSocket disconnect timed out")
        
        # 4. Close REST session
        if self.rest_connector:
            try:
                logger.info("Closing REST session...")
                await asyncio.wait_for(
                    self.rest_connector.__aexit__(None, None, None),
                    timeout=5.0
                )
            except asyncio.TimeoutError:
                logger.error("REST connector close timed out")
        
        # 5. Flush metrics
        if self.metrics:
            try:
                logger.info("Flushing metrics...")
                # Prometheus client doesn't need explicit flush, but log final state
                self.metrics.bot_uptime_seconds.set(time.time() - self.start_time)
            except Exception as e:
                logger.error(f"Failed to flush metrics: {e}")
        
        # 6. Close recorder
        if self.data_recorder:
            try:
                logger.info("Closing data recorder...")
                await asyncio.wait_for(self.data_recorder.close(), timeout=5.0)
            except asyncio.TimeoutError:
                logger.error("Recorder close timed out")
        
        # 7. Save final snapshots
        try:
            logger.info("Saving final snapshots...")
            await asyncio.wait_for(self._save_all_snapshots(), timeout=5.0)
        except asyncio.TimeoutError:
            logger.error("Snapshot save timed out")
        
        # 8. Stop web server
        if self.web_runner:
            try:
                logger.info("Stopping web server...")
                await asyncio.wait_for(self.web_runner.cleanup(), timeout=3.0)
            except asyncio.TimeoutError:
                logger.error("Web server stop timed out")
        
        elapsed = time.time() - start_time
        logger.info(f"Shutdown complete in {elapsed:.2f}s")
    
    async def _save_all_snapshots(self) -> None:
        """Save all state snapshots atomically."""
        snapshots = [
            ('allocator', self._save_allocator_snapshot),
            ('throttle', self._save_throttle_snapshot),
            ('rollout', self._save_rollout_snapshot),
        ]
        
        for name, func in snapshots:
            try:
                await func()
                logger.debug(f"Saved {name} snapshot")
            except Exception as e:
                logger.error(f"Failed to save {name} snapshot: {e}")

# Signal handlers
def setup_signal_handlers(bot: MarketMakerBot):
    """Setup OS signal handlers for graceful shutdown."""
    loop = asyncio.get_event_loop()
    
    def handle_signal(signum, frame):
        logger.info(f"Received signal {signum}, initiating shutdown...")
        asyncio.create_task(bot.stop())
    
    signal.signal(signal.SIGINT, handle_signal)
    signal.signal(signal.SIGTERM, handle_signal)
    
    # Windows-specific
    if hasattr(signal, 'SIGBREAK'):
        signal.signal(signal.SIGBREAK, handle_signal)

# –í main():
async def main():
    bot = MarketMakerBot(...)
    setup_signal_handlers(bot)
    
    try:
        await bot.initialize()
        await bot.start()
    except KeyboardInterrupt:
        pass
    finally:
        await bot.stop()
```

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] –í—Å–µ background tasks –æ—Ç–º–µ–Ω—è—é—Ç—Å—è
- [ ] WebSocket/REST –∑–∞–∫—Ä—ã–≤–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- [ ] Snapshots —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∞—Ç–æ–º–∞—Ä–Ω–æ
- [ ] Signal handlers –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç SIGINT/SIGTERM
- [ ] Shutdown –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è –∑–∞ <30 —Å–µ–∫—É–Ω–¥
- [ ] –¢–µ—Å—Ç: `kill -TERM <pid>` ‚Üí graceful shutdown

---

## ‚ö†Ô∏è –í–´–°–û–ö–ò–ï (–∏—Å–ø—Ä–∞–≤–∏—Ç—å –≤ —Ç–µ—á–µ–Ω–∏–µ –Ω–µ–¥–µ–ª–∏)

### SEC-002: Security scan –≤ CI
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P1 (–í—ã—Å–æ–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å  
**–í—Ä–µ–º—è:** 1 —á–∞—Å  

**–°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª:** `.github/workflows/security.yml`

```yaml
name: Security Scan

on:
  push:
    branches: [main, develop]
  pull_request:
  schedule:
    - cron: '0 2 * * 1'  # –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ –ø–æ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞–º

jobs:
  python-security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      
      - name: Install security tools
        run: |
          pip install pip-audit safety bandit
      
      - name: Pip audit
        run: pip-audit --requirement requirements.txt --format json --output pip-audit.json
        continue-on-error: true
      
      - name: Safety check
        run: safety check --file requirements.txt --json --output safety.json
        continue-on-error: true
      
      - name: Bandit static analysis
        run: bandit -r src/ -f json -o bandit.json
        continue-on-error: true
      
      - name: Upload security reports
        uses: actions/upload-artifact@v4
        with:
          name: security-reports-python
          path: |
            pip-audit.json
            safety.json
            bandit.json
      
      - name: Fail on critical vulnerabilities
        run: |
          if grep -q '"severity":"critical"' pip-audit.json safety.json bandit.json; then
            echo "‚ùå Critical vulnerabilities found!"
            exit 1
          fi
  
  rust-security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      
      - name: Install cargo-audit
        run: cargo install cargo-audit --locked
      
      - name: Cargo audit
        working-directory: rust
        run: cargo audit --json > ../cargo-audit.json
        continue-on-error: true
      
      - name: Upload cargo audit report
        uses: actions/upload-artifact@v4
        with:
          name: security-reports-rust
          path: cargo-audit.json
```

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] Security workflow –¥–æ–±–∞–≤–ª–µ–Ω –≤ CI
- [ ] –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥—ã–π PR –∏ commit –≤ main
- [ ] –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–π scheduled run
- [ ] Fail –Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —É—è–∑–≤–∏–º–æ—Å—Ç—è—Ö

---

### SEC-003: –û–±–µ—Ä–Ω—É—Ç—å –ª–æ–≥–∏ —á–µ—Ä–µ–∑ redact()
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P1 (–í—ã—Å–æ–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å  
**–í—Ä–µ–º—è:** 2 —á–∞—Å–∞  

**–°–æ–∑–¥–∞—Ç—å:** `src/common/logging.py`

```python
import logging
import sys
from typing import Any
from src.common.redact import redact, DEFAULT_PATTERNS

class SecureFormatter(logging.Formatter):
    """Log formatter that redacts sensitive data."""
    
    def format(self, record: logging.LogRecord) -> str:
        # Redact message
        if isinstance(record.msg, str):
            record.msg = redact(record.msg, DEFAULT_PATTERNS)
        
        # Redact args
        if record.args:
            record.args = tuple(
                redact(str(arg), DEFAULT_PATTERNS) if isinstance(arg, (str, bytes)) else arg
                for arg in record.args
            )
        
        # Redact exception info
        if record.exc_info and record.exc_info[1]:
            exc_str = str(record.exc_info[1])
            record.exc_text = redact(exc_str, DEFAULT_PATTERNS)
        
        return super().format(record)

def setup_secure_logging(level: str = "INFO"):
    """Setup secure logging with redaction."""
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(SecureFormatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    ))
    
    root_logger = logging.getLogger()
    root_logger.setLevel(getattr(logging, level.upper()))
    root_logger.addHandler(handler)
    
    return root_logger

# Replace all print() with logger
def secure_print(*args, **kwargs):
    """Secure replacement for print() that redacts secrets."""
    msg = ' '.join(str(arg) for arg in args)
    redacted = redact(msg, DEFAULT_PATTERNS)
    print(redacted, **kwargs)
```

**–ó–∞–º–µ–Ω–∏—Ç—å –≤–æ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö:**
```python
# ‚ùå –ë—ã–ª–æ:
print(f"Config: {config}")

# ‚úÖ –°—Ç–∞–ª–æ:
logger.info("Config loaded", config=config.to_sanitized())
```

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] –í—Å–µ `print()` –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ `logger.*`
- [ ] SecureFormatter –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–æ –≤—Å–µ–º –ª–æ–≥–∞–º
- [ ] –¢–µ—Å—Ç: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥–∞ —Å API –∫–ª—é—á–∞–º–∏ ‚Üí –∫–ª—é—á–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω—ã

---

### PERF-001: Connection pooling –≤ REST
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P1 (–í—ã—Å–æ–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å  
**–í—Ä–µ–º—è:** 1 —á–∞—Å  
**–§–∞–π–ª:** `src/connectors/bybit_rest.py:103-106`

**–ò–∑–º–µ–Ω–µ–Ω–∏–µ:**
```python
async def __aenter__(self):
    """Async context manager entry with connection pooling."""
    connector = aiohttp.TCPConnector(
        limit=100,              # Max 100 connections total
        limit_per_host=20,      # Max 20 to Bybit API
        ttl_dns_cache=300,      # Cache DNS for 5 min
        force_close=False,      # Enable keep-alive
        enable_cleanup_closed=True,
    )
    
    timeout = aiohttp.ClientTimeout(
        total=30,       # Total request timeout
        connect=10,     # Connection timeout
        sock_read=20    # Socket read timeout
    )
    
    self.session = aiohttp.ClientSession(
        connector=connector,
        timeout=timeout,
        headers={'Content-Type': 'application/json'},
        json_serialize=lambda obj: orjson.dumps(obj).decode(),  # Fast JSON
        raise_for_status=False  # Handle status manually
    )
    
    self.connected = True
    logger.info("REST connector initialized with connection pooling")
    return self
```

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] Connection pooling –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- [ ] Keep-alive –≤–∫–ª—é—á–µ–Ω
- [ ] DNS –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ
- [ ] Benchmark: latency —É–º–µ–Ω—å—à–∏–ª–∞—Å—å –Ω–∞ 10-15%

---

### PERF-002: –ó–∞–º–µ–Ω–∏—Ç—å json –Ω–∞ orjson –≤–µ–∑–¥–µ
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P1 (–í—ã—Å–æ–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å  
**–í—Ä–µ–º—è:** 2 —á–∞—Å–∞  

**–°–æ–∑–¥–∞—Ç—å:** `src/common/json_io.py`

```python
"""Centralized JSON I/O with orjson for performance."""
import orjson
from pathlib import Path
from typing import Any, Dict, Union

def dumps(obj: Any, *, pretty: bool = False) -> bytes:
    """Serialize to JSON bytes (fast)."""
    options = orjson.OPT_SORT_KEYS
    if pretty:
        options |= orjson.OPT_INDENT_2
    return orjson.dumps(obj, option=options)

def loads(data: Union[bytes, str]) -> Any:
    """Deserialize from JSON bytes or string (fast)."""
    if isinstance(data, str):
        data = data.encode('utf-8')
    return orjson.loads(data)

def load_file(path: Union[Path, str]) -> Dict[str, Any]:
    """Load JSON from file (fast)."""
    path = Path(path)
    return orjson.loads(path.read_bytes())

def save_file(obj: Any, path: Union[Path, str], *, pretty: bool = False) -> None:
    """Save JSON to file atomically (fast)."""
    path = Path(path)
    tmp = path.with_suffix('.tmp')
    
    options = orjson.OPT_SORT_KEYS
    if pretty:
        options |= orjson.OPT_INDENT_2
    
    tmp.write_bytes(orjson.dumps(obj, option=options) + b'\n')
    tmp.replace(path)
```

**–ó–∞–º–µ–Ω–∏—Ç—å –≤–æ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö:**
```python
# ‚ùå –ë—ã–ª–æ:
import json
data = json.loads(text)
json.dump(obj, f)

# ‚úÖ –°—Ç–∞–ª–æ:
from src.common.json_io import loads, save_file
data = loads(text)
save_file(obj, path)
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
- `tools/soak/kpi_gate.py`
- `tools/rehearsal/pre_live_pack.py`
- `tools/ci/full_stack_validate.py`
- `src/common/artifacts.py`
- –í—Å–µ –º–µ—Å—Ç–∞ —Å `json.loads()` / `json.dumps()`

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] –í—Å–µ `json.*` –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ `orjson` (—á–µ—Ä–µ–∑ –æ–±–µ—Ä—Ç–∫—É)
- [ ] Benchmark: JSON serialization –Ω–∞ 3-5x –±—ã—Å—Ç—Ä–µ–µ
- [ ] –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç

---

## üìù –°–†–ï–î–ù–ò–ï (backlog –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π —Å–ø—Ä–∏–Ω—Ç)

### ARCH-001: –†–∞–∑–±–∏—Ç—å cli/run_bot.py –Ω–∞ –º–æ–¥—É–ª–∏
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P2 (–°—Ä–µ–¥–Ω–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞  
**–í—Ä–µ–º—è:** 4 —á–∞—Å–∞  

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:**
```
cli/
‚îú‚îÄ‚îÄ run_bot.py              # Entry point (100 LOC)
‚îú‚îÄ‚îÄ bot/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ core.py             # MarketMakerBot class (init, lifecycle)
‚îÇ   ‚îú‚îÄ‚îÄ web_server.py       # HTTP endpoints
‚îÇ   ‚îú‚îÄ‚îÄ admin_api.py        # Admin endpoints (/admin/*)
‚îÇ   ‚îú‚îÄ‚îÄ snapshots.py        # State persistence
‚îÇ   ‚îú‚îÄ‚îÄ hot_reload.py       # Config reload logic
‚îÇ   ‚îî‚îÄ‚îÄ background_tasks.py # Rebalance, scheduler watcher, etc.
```

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] run_bot.py < 200 —Å—Ç—Ä–æ–∫
- [ ] –ö–∞–∂–¥—ã–π –º–æ–¥—É–ª—å < 500 —Å—Ç—Ä–æ–∫
- [ ] –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] Import time –Ω–µ —É–≤–µ–ª–∏—á–∏–ª—Å—è

---

### CONFIG-001: –†–∞–∑–±–∏—Ç—å config.py –Ω–∞ –º–æ–¥—É–ª–∏
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P2 (–°—Ä–µ–¥–Ω–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è  
**–í—Ä–µ–º—è:** 3 —á–∞—Å–∞  

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:**
```
src/common/config/
‚îú‚îÄ‚îÄ __init__.py             # Public API
‚îú‚îÄ‚îÄ base.py                 # AppConfig, ConfigLoader
‚îú‚îÄ‚îÄ strategy.py             # StrategyConfig
‚îú‚îÄ‚îÄ risk.py                 # RiskConfig, GuardsConfig
‚îú‚îÄ‚îÄ portfolio.py            # PortfolioConfig, AllocatorConfig
‚îú‚îÄ‚îÄ monitoring.py           # MonitoringConfig
‚îú‚îÄ‚îÄ rollout.py              # RolloutConfig, RolloutRampConfig
‚îú‚îÄ‚îÄ validation.py           # validate_invariants, diff_runtime_safe
‚îî‚îÄ‚îÄ helpers.py              # cfg_hash_sanitized, get_git_sha
```

**–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- [ ] –ö–∞–∂–¥—ã–π –º–æ–¥—É–ª—å < 300 —Å—Ç—Ä–æ–∫
- [ ] –ù–µ—Ç —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
- [ ] –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç

---

### OBS-001: Prometheus Alert Rules
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P2 (–°—Ä–µ–¥–Ω–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** –ù–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å  
**–í—Ä–µ–º—è:** 2 —á–∞—Å–∞  

–°–º. –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç, —Ä–∞–∑–¥–µ–ª 7.1.2.

---

## üîß –ù–ò–ó–ö–ò–ï (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–æ–ª–≥)

### RUST-001: –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ apply_snapshot()
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P3 (–ù–∏–∑–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Rust  
**–í—Ä–µ–º—è:** 1 —á–∞—Å  

–°–º. –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç, —Ä–∞–∑–¥–µ–ª 1.3.

---

### RUST-002: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è reorder()
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** P3 (–ù–∏–∑–∫–∏–π)  
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Rust  
**–í—Ä–µ–º—è:** 30 –º–∏–Ω—É—Ç  

–°–º. –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç, —Ä–∞–∑–¥–µ–ª 2.3.1.

---

## üìä –¢—Ä–µ–∫–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º:

| –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç | –í—Å–µ–≥–æ | –í—ã–ø–æ–ª–Ω–µ–Ω–æ | –í —Ä–∞–±–æ—Ç–µ | –ù–µ –Ω–∞—á–∞—Ç–æ |
|-----------|-------|-----------|----------|-----------|
| P0 (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π) | 5 | 0 | 0 | 5 |
| P1 (–í—ã—Å–æ–∫–∏–π) | 3 | 0 | 0 | 3 |
| P2 (–°—Ä–µ–¥–Ω–∏–π) | 3 | 0 | 0 | 3 |
| P3 (–ù–∏–∑–∫–∏–π) | 2 | 0 | 0 | 2 |
| **–ò–¢–û–ì–û** | **13** | **0** | **0** | **13** |

### Roadmap:

**Week 1 (—Ç–µ–∫—É—â–∞—è):**
- [ ] SEC-001, SOAK-001, SOAK-002, NET-001, SYS-001
- [ ] Milestone: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã
- [ ] Deliverable: 24-—á–∞—Å–æ–≤–æ–π soak-—Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω

**Week 2:**
- [ ] SEC-002, SEC-003, PERF-001, PERF-002
- [ ] Milestone: –í—ã—Å–æ–∫–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∑–∞–∫—Ä—ã—Ç—ã
- [ ] Deliverable: 72-—á–∞—Å–æ–≤–æ–π soak-—Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω

**Week 3:**
- [ ] ARCH-001, CONFIG-001, OBS-001
- [ ] Milestone: –°—Ä–µ–¥–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∑–∞–∫—Ä—ã—Ç—ã
- [ ] Deliverable: Production-ready release

**Week 4:**
- [ ] RUST-001, RUST-002
- [ ] Milestone: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–æ–ª–≥ —Å–æ–∫—Ä–∞—â–µ–Ω
- [ ] Deliverable: v0.2.0 released

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-10-01  
**–°–ª–µ–¥—É—é—â–∏–π review:** 2025-10-08

